{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "from scipy.signal import resample\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from transformers import WhisperTokenizer\n",
    "from transformers import WhisperFeatureExtractor\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "import evaluate\n",
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove only \", ', and ,\n",
    "    text = re.sub(r'[\",\\']', '', text)\n",
    "    # Optional: remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "wer  = evaluate.load('wer')\n",
    "\n",
    "\n",
    "\n",
    "def down_sample_audio(audio_original, original_sample_rate):\n",
    "    target_sample_rate = 16000\n",
    "\n",
    "    # Calculate the number of samples for the target sample rate\n",
    "    num_samples = int(len(audio_original) * target_sample_rate / original_sample_rate)\n",
    "\n",
    "    # Resample the audio array to the target sample rate\n",
    "    downsampled_audio = resample(audio_original, num_samples)\n",
    "\n",
    "    return downsampled_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\",language='bengali',task='translate')\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\",language='bengali',task='translate')\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset,concatenate_datasets\n",
    "\n",
    "asr_dataset = load_dataset(\"Mohan-diffuser/odia-english-ASR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 62,\n",
       " 'num_samples': 159360,\n",
       " 'path': '/home/mohan.dash/.cache/huggingface/datasets/downloads/extracted/e2fcce8118681935ebfe4ee7e9b039155b764427d2269ffa5a66a0328fe9ec55/10020140876560357327.wav',\n",
       " 'audio': {'path': '10020140876560357327.wav',\n",
       "  'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00582969,\n",
       "         -0.00332552, -0.00426018]),\n",
       "  'sampling_rate': 16000},\n",
       " 'transcription': 'ତାଙ୍କର 2 ଘଣ୍ଟାର ଭାଷଣରେ ସେ କହିଥିଲେ ଯେ ଆଜି apple ତାର ଫୋନକୁ ପୁଣି ଉଦ୍ଭାବନ କରିବାକୁ ଯାଉଛି ଆମେ ଆଜି ଇତିହାସ ରଚିବାକୁ ଯାଉଛୁ',\n",
       " 'raw_transcription': 'ତାଙ୍କର 2 ଘଣ୍ଟାର ଭାଷଣରେ ସେ କହିଥିଲେ ଯେ \"ଆଜି Apple ତାର ଫୋନକୁ ପୁଣି ଉଦ୍ଭାବନ କରିବାକୁ ଯାଉଛି, ଆମେ ଆଜି ଇତିହାସ ରଚିବାକୁ ଯାଉଛୁ।\"',\n",
       " 'gender': 1,\n",
       " 'lang_id': 72,\n",
       " 'language': 'Oriya',\n",
       " 'lang_group_id': 4,\n",
       " 'eng_translation': 'In his 2-hour speech, he said that today Apple is going to reinvent its phone. We are going to make history today.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asr_dataset['train'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_transcription_lengths = []\n",
    "\n",
    "tokenized_text = tokenizer(asr_dataset['train']['eng_translation']).input_ids\n",
    "\n",
    "for text in tokenized_text:\n",
    "    list_of_transcription_lengths.append(len(text))\n",
    "    # break\n",
    "\n",
    "plt.hist(list_of_transcription_lengths)\n",
    "plt.xlabel(\"sentence length\")\n",
    "plt.ylabel(\"number of transcripts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------0------\n",
      "true : in his 2-hour speech he said that today apple is going to reinvent its phone. we are going to make history today. \n",
      "pred :  I have been in the forest for 2 hours and I am going to do some work on the water and the fire.\n",
      "\n",
      " \n",
      "-------1------\n",
      "true : the games started with good weather in the morning 10:00 and apart from a midnight thunderstorm which cleared up quickly it was a perfect day for 7th rugby. \n",
      "pred :  The forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely destroyed by the heavy rain and the forest was completely\n",
      "\n",
      " \n",
      "-------2------\n",
      "true : if a rider is thrown from the horse but gets stuck in the saddle the horse will pull away if they run. there are a number of precautions that can be taken to avoid this risk. \n",
      "pred :  If the root is damaged, the root will be damaged and the root will be damaged. This is the reason why many people can't afford to do this.\n",
      "\n",
      " \n",
      "-------3------\n",
      "true : in 1995 he was named the best player in the history of partizan. \n",
      "pred :  I felt like I was going to be a part of this tradition\n",
      "\n",
      " \n",
      "-------4------\n",
      "true : it is still in production but more importantly the image sensor formats of digital cameras have inherited their aspect ratios. \n",
      "pred :  I am going to show you the details of the camera in detail.\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model.eval()\n",
    "model.config.use_cache=True\n",
    "\n",
    "for idx in range(5):\n",
    "\n",
    "    target = normalize_text(asr_dataset['train'][idx]['eng_translation'])\n",
    "    audio_original = asr_dataset['train'][idx]['audio']['array']\n",
    "    original_sample_rate = asr_dataset['train'][idx]['audio']['sampling_rate']\n",
    "\n",
    "    audio_16000 = down_sample_audio(audio_original, original_sample_rate)\n",
    "\n",
    "    input_feature = feature_extractor(raw_speech=audio_16000,\n",
    "                                    sampling_rate=16000,\n",
    "                                    return_tensors='pt').input_features\n",
    "\n",
    "    with torch.no_grad():\n",
    "        op = model.generate(input_feature.to('cuda'), language='bengali', task='translate')\n",
    "\n",
    "\n",
    "    text_pred =  tokenizer.batch_decode(op,skip_special_tokens=True )[0]\n",
    "\n",
    "    print(f'-------{idx}------')\n",
    "    print(f'true : {target} \\npred : {text_pred}')\n",
    "    print('\\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class whisper_training_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, max_len):#daatset is huggingface dataset object\n",
    "        self.dataset = dataset\n",
    "        self.max_len = max_len\n",
    "        self.bos_token = model.config.decoder_start_token_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "\n",
    "        audio_data = down_sample_audio(item['audio'][\"array\"], item['audio'][\"sampling_rate\"])\n",
    "        input_features = feature_extractor(audio_data, sampling_rate=16000,return_tensors='pt').input_features[0]\n",
    "\n",
    "        # Process the transcription\n",
    "        transcription = normalize_text(item['eng_translation'])\n",
    "\n",
    "        # Create labels\n",
    "        labels = tokenizer(transcription, padding=\"max_length\", max_length=self.max_len, truncation=True, return_tensors=\"pt\")\n",
    "        labels = labels[\"input_ids\"].masked_fill(labels['attention_mask'].ne(1), -100)\n",
    "        labels = labels[0][1:]\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"input_features\": input_features,\n",
    "            \"labels\": labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = whisper_training_dataset(dataset=asr_dataset['train'], max_len=60)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=8,  # Adjust batch size as needed\n",
    "    shuffle=True,  # Shuffle data during training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model):\n",
    "\n",
    "    device='cuda'\n",
    "\n",
    "    test_dataset = whisper_training_dataset(dataset=asr_dataset['validation'], max_len=60)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=8,  # Adjust batch size as needed\n",
    "        shuffle=True,  # Shuffle data during training\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    predictions=[]\n",
    "    references=[]\n",
    "\n",
    "    for batch in tqdm(test_dataloader,total=len(test_dataloader)):\n",
    "        \n",
    "\n",
    "        model.eval()  # Set model to training mode\n",
    "        model.config.use_cache = True\n",
    "\n",
    "        input_features, labels = batch[\"input_features\"].to(device), batch[\"labels\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(input_features=input_features,language='bengali', task='translate')\n",
    "                        \n",
    "        decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        predictions.extend(decoded_preds)\n",
    "        references.extend(decoded_labels)\n",
    "\n",
    "    WER = wer.compute(predictions=predictions, references=references) * 100\n",
    "\n",
    "    return WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [04:38<00:00,  5.67s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "204.23869893712384"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WER before the training\n",
    "torch.cuda.empty_cache()\n",
    "evaluation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 10,616,832 || all params: 252,351,744 || trainable%: 4.2072\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, PeftModel, LoraModel, LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(r=64, lora_alpha=64, target_modules=[\"q_proj\", \"v_proj\", \"q_proj\", \"out_proj\"], lora_dropout=0.05, bias=\"none\")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# model.save_pretrained('lora_model')\n",
    "\n",
    "# model = PeftModel.from_pretrained(model,model_id='lora_model')\n",
    "\n",
    "# for n,p in model.named_parameters():\n",
    "#     print(n,p.requires_grad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = whisper_training_dataset(dataset=asr_dataset['validation'], max_len=60)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,  # Adjust batch size as needed\n",
    "    shuffle=True,  # Shuffle data during training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m gradient_accumulation_steps  \u001b[38;5;66;03m# Scale the loss\u001b[39;00m\n\u001b[1;32m     35\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 36\u001b[0m accumulated_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m gradient_accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     39\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model.config.use_cache = False\n",
    "model.train()\n",
    "\n",
    "device = 'cuda'\n",
    "# Filter parameters with requires_grad=True\n",
    "requires_grad_params = filter(lambda x: x[1].requires_grad, model.parameters())\n",
    "optimizer = torch.optim.AdamW(requires_grad_params, lr=5e-4)  # Only for LoRA Training\n",
    "\n",
    "max_epochs = 4\n",
    "gradient_accumulation_steps = 4\n",
    "\n",
    "running_train_loss = []\n",
    "running_val_loss = []\n",
    "running_wer = []\n",
    "\n",
    "global_step = 0\n",
    "accumulated_loss = 0\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, total=len(train_dataloader), leave=False)):\n",
    "\n",
    "        model.train()\n",
    "        input_features, labels = batch[\"input_features\"].to(device), batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_features, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss = loss / gradient_accumulation_steps  # Scale the loss\n",
    "\n",
    "        loss.backward()\n",
    "        accumulated_loss += loss.item()\n",
    "\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            running_train_loss.append(accumulated_loss)\n",
    "            accumulated_loss = 0\n",
    "            global_step += 1\n",
    "\n",
    "            # Validation loop\n",
    "            if global_step % 50 == 0:\n",
    "                model.eval()\n",
    "                val_loss = 0.0\n",
    "                with torch.no_grad():\n",
    "                    for val_batch in test_dataloader:\n",
    "                        val_input, val_labels = val_batch[\"input_features\"].to(device), val_batch[\"labels\"].to(device)\n",
    "                        val_outputs = model(val_input, labels=val_labels)\n",
    "                        val_loss += val_outputs.loss.item()\n",
    "                val_loss /= len(test_dataloader)\n",
    "                running_val_loss.append(val_loss)\n",
    "\n",
    "                # Plot both train and val loss\n",
    "                clear_output(wait=True)\n",
    "                plt.plot(running_train_loss, label='Training Loss')\n",
    "                plt.plot([i * 5 for i in range(len(running_val_loss))], running_val_loss, label='Validation Loss')\n",
    "                plt.xlabel('Steps')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.legend()\n",
    "                plt.grid()\n",
    "                plt.title(f'Epoch {epoch+1}, Step {step+1}')\n",
    "                plt.show()\n",
    "\n",
    "            # Save model every 100 global steps\n",
    "            if global_step % 100 == 0:\n",
    "                model.save_pretrained('lora_model')\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wer = evaluation(model)  # Assuming evaluation returns WER\n",
    "    running_wer.append(wer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[157.30567294147778, 153.37431169163784]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_wer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "from scipy.signal import resample\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from transformers import WhisperTokenizer\n",
    "from transformers import WhisperFeatureExtractor\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "\n",
    "import evaluate\n",
    "#pip install jiwer\n",
    "\n",
    "wer  = evaluate.load('wer')\n",
    "\n",
    "\n",
    "\n",
    "def down_sample_audio(audio_original, original_sample_rate):\n",
    "    target_sample_rate = 16000\n",
    "\n",
    "    # Calculate the number of samples for the target sample rate\n",
    "    num_samples = int(len(audio_original) * target_sample_rate / original_sample_rate)\n",
    "\n",
    "    # Resample the audio array to the target sample rate\n",
    "    downsampled_audio = resample(audio_original, num_samples)\n",
    "\n",
    "    return downsampled_audio\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\",language='bengali',task='translate')\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\",language='bengali',task='translate')\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\").to('cuda')\n",
    "\n",
    "model = PeftModel.from_pretrained(model, 'lora_adapter', is_trainable=False)\n",
    "\n",
    "model.eval()\n",
    "model.to('cuda')\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------0------\n",
      "true : Animals such as elephants and giraffes have a tendency to come up to take a closer look at cars and standard equipment that looks good. \n",
      "pred : Consultation is an excellent way to see the car and well seen by the hand-made animals of the pastures.\n",
      "\n",
      " \n",
      "-------1------\n",
      "true : Please treat this place with the honesty, seriousness, and respect it deserves. Don't make jokes about the Holocaust or the Nazis. \n",
      "pred : Sympathy in the place is hard to think of with deep feelings and thoughts about alcoholics or alcoholic topics.\n",
      "\n",
      " \n",
      "-------2------\n",
      "true : 108 types of Chhapan Bhog In Hinduism, 56 types of food items such as sweet fruits, almond dishes, etc. which are offered to God were offered to Baba Shyam. \n",
      "pred : The 18-day anniversary of the event was celebrated by the Hinduism and by the sweet fruit-ed-grain season as well as the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season of the season\n",
      "\n",
      " \n",
      "-------3------\n",
      "true : Currently widely available throughout the archipelago, Javanese cuisine has a long tradition of seasonal dishes that are flavored with Javanese peanut chili sugar, especially Javanese coconut sugar, and various aromatic spices. \n",
      "pred : Early in the archipelago of all Archipelago, the island has an important part in the Brazilian economy, such as the Chinese word for javanejman, china, and other related problems.\n",
      "\n",
      " \n",
      "-------4------\n",
      "true : Initially, clothing was heavily influenced by the Byzantine culture of the East. \n",
      "pred : In the beginning, the taste of the past has been influenced by the white white sandal.\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model.eval()\n",
    "model.config.use_cache=True\n",
    "\n",
    "for idx in range(5):\n",
    "\n",
    "    target = asr_dataset['validation'][idx]['eng_translation']\n",
    "    audio_original = asr_dataset['validation'][idx]['audio']['array']\n",
    "    original_sample_rate = asr_dataset['validation'][idx]['audio']['sampling_rate']\n",
    "\n",
    "    audio_16000 = down_sample_audio(audio_original, original_sample_rate)\n",
    "\n",
    "    input_feature = feature_extractor(raw_speech=audio_16000,\n",
    "                                    sampling_rate=16000,\n",
    "                                    return_tensors='pt').input_features\n",
    "\n",
    "    with torch.no_grad():\n",
    "        op = model.generate(input_feature.to('cuda'), language='bengali', task='translate')\n",
    "\n",
    "\n",
    "    text_pred =  tokenizer.batch_decode(op,skip_special_tokens=True )[0]\n",
    "\n",
    "    print(f'-------{idx}------')\n",
    "    print(f'true : {target} \\npred : {text_pred}')\n",
    "    print('\\n ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
